<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML>
<HEAD>
 <META NAME="GENERATOR" CONTENT="SGML-Tools 1.0.9">
 <TITLE>Linux 2.4 Advanced Routing HOWTO: More queueing disciplines</TITLE>
 <LINK HREF="Adv-Routing-HOWTO-10.html" REL=next>
 <LINK HREF="Adv-Routing-HOWTO-8.html" REL=previous>
 <LINK HREF="Adv-Routing-HOWTO.html#toc9" REL=contents>
<SCRIPT src="../menu.js"> function BeginPage() {} function EndPage() {} </SCRIPT> </HEAD> <BODY bgcolor=#EEEEFF MARGINHEIGHT=0 MARGINWIDTH=0> <SCRIPT>BeginPage(1, 8, 1);</SCRIPT>
<A HREF="Adv-Routing-HOWTO-10.html"><IMG SRC="../img/next.gif" ALT="Next"></A>
<A HREF="Adv-Routing-HOWTO-8.html"><IMG SRC="../img/prev.gif" ALT="Previous"></A>
<A HREF="Adv-Routing-HOWTO.html#toc9"><IMG SRC="../img/toc.gif" ALT="Contents"></A>
<HR>
<H2><A NAME="s9">9. More queueing disciplines</A></H2>

<P>The Linux kernel offers us lots of queueing disciplines. By far the most
widely used is the pfifo_fast queue - this is the default. This also
explains why these advanced features are so robust. They are nothing more
than 'just another queue'.
<P>Each of these queues has specific strengths and weaknesses. Not all of them
may be as well tested.
<H2><A NAME="ss9.1">9.1 pfifo_fast</A>
</H2>

<P>This queue is, as the name says, First In, First Out, which means that no
packet receives special treatment. At least, not quite. This queue has 3 so
called 'bands'. Within each band, FIFO rules apply. However, as long as
there are packets waiting in band 0, band 1 won't be processed. Same goes
for band 1 and band 2.
<H2><A NAME="ss9.2">9.2 Stochastic Fairness Queueing</A>
</H2>

<P>SFQ, as said earlier, is not quite deterministic, but works (on average).
Its main benefits are that it requires little CPU and memory. 'Real' fair
queueing requires that the kernel keep track of all running sessions.
<P>Stochastic Fairness Queueing (SFQ) is a simple implementation
of fair queueing algorithms family. It's less accurate than
others, but it also requires less calculations while being
almost perfectly fair.
<P>The key word in SFQ is conversation (or flow), being a sequence
of data packets having enough common parameters to distinguish
it from other conversations. The parameters used in case of
IP packets are source and destination address, and the protocol
number.
<P>SFQ consists of dynamically allocated number of FIFO queues,
one queue for one conversation. The discipline runs in round-robin,
sending one packet from each FIFO in one turn, and this is why
it's called fair. The main advantage of SFQ is that it allows
fair sharing the link between several applications and prevent
bandwidth take-over by one client. SFQ however cannot determine
interactive flows from bulk ones -- one usually needs to do
the selection with CBQ before, and then direct the bulk traffic
into SFQ.
<P>
<P>
<H2><A NAME="ss9.3">9.3 Token Bucket Filter</A>
</H2>

<P>The Token Bucket Filter (TBF) is a simple queue, that only passes packets
arriving at rate in bounds of some administratively set limit, with
possibility to buffer short bursts.
<P>The TBF implementation consists of a buffer (bucket), constatly filled by
some virtual pieces of information called tokens, at specific rate (token
rate). The most important parameter of the bucket is its size, that is
number of tokens it can store.
<P>Each arriving token lets one incoming data packet of out the queue and is
then deleted from the bucket. Associating this algorithm with the two flows
-- token and data, gives us three possible scenarios:
<P>
<UL>
<LI> The data arrives into TBF at rate <EM>equal</EM> the rate of incoming
tokens. In this case each incoming packet has its matching token and passes
the queue without delay.
</LI>
<LI> The data arrives into TBF at rate <EM>smaller</EM> than the token rate.
Only some tokens are deleted at output of each data packet sent out the
queue, so the tokens accumulate, up to the bucket size. The saved tokens can
be then used to send data over the token rate, if short data burst occurs.
</LI>
<LI> The data arrives into TBF at rate <EM>bigger</EM> than the token rate. In
this case filter overrun occurs -- incoming data can be only sent out
without loss until all accumulated tokens are used. After that, overlimit
packets are dropped.
</LI>
</UL>
<P>
<P> The last scenario is very important, because it allows to
administratively shape the bandwidth available to data, passing the filter.
The accumulation of tokens allows short burst of overlimit data to be still
passed without loss, but any lasting overload will cause packets to be
constantly dropped.
<P>The Linux kernel seems to go beyond this specification, and also allows us
to limit the speed of the burst transmission. However, Alexey warns us:
<P>
<BLOCKQUOTE><CODE>
Note that the peak rate TBF is much more tough: with MTU 1500
P_crit = 150Kbytes/sec. So, if you need greater peak
rates, use alpha with HZ=1000 :-)
</CODE></BLOCKQUOTE>
<P>FIXME: is this still true with TSC (pentium+)? Well sort of
<P>FIXME: if not, add section on raising HZ
<P>
<H2><A NAME="ss9.4">9.4 Random Early Detect</A>
</H2>

<P>RED has some extra smartness built in. When a TCP/IP session starts, neither
end knows the amount of bandwidth available. So TCP/IP starts to transmit
slowly and goes faster and faster, though limited by the latency at which
ACKs return.
<P>Once a link is filling up, RED starts dropping packets, which indicate to
TCP/IP that the link is congested, and that it should slow down. The smart
bit is that RED simulates real congestion, and starts to drop some packets
some time before the link is entirely filled up. Once the link is completely
saturated, it behaves like a normal policer.
<P>For more information on this, see the Backbone chapter.
<P>
<H2><A NAME="ss9.5">9.5 Ingress policer qdisc</A>
</H2>

<P> 
<P>The Ingress qdisc comes in handy if you need to ratelimit a host without
help from routers or other Linux boxes. You can police incoming bandwidth
and drop packets when this bandwidth exceeds your desired rate. This can
save your host from a SYN flood, for example, and also works to slow down
TCP/IP, which responds to dropped packets by reducing speed.
<P>FIXME: instead of dropping, can we also assign it to a real queue?
<P>FIXME: shaping by dropping packets seems less desirable than using, for
example, a token bucket filter. Not sure though, Cisco CAR works this
way, and people appear happy with it.
<P>See the reference to 
<A HREF="Adv-Routing-HOWTO-17.html#CAR">IOS Committed Access Rate</A> at the
end of this document.
<P>
<P>In short: you can use this to limit how fast your computer downloads files,
thus leaving more of the available bandwidth for others.
<P>See the section on protecting your host from SYN floods for an example on
how this works.
<H2><A NAME="ss9.6">9.6 WRR</A>
</H2>

<P>This qdisc is not included in the standard kernels but can be downloaded from 
<A HREF="http://wipl-wrr.dkik.dk/wrr/">http://wipl-wrr.dkik.dk/wrr/</A>. 
Currently the qdisc is only tested with Linux 2.2 kernels but it will 
probably work with 2.4 kernels too.
<P>The WRR qdisc distributes bandwidth between its classes using the weighted 
round robin scheme. That is, like the CBQ qdisc it contains classes 
into which arbitrary qdiscs can be plugged. All classes which have sufficient 
demand will get bandwidth proportional to the weights associated with the classes.
The weights can be set manually using the <CODE>tc</CODE> program. But they
can also be made automatically decreasing for classes transferring much data.
<P>The qdisc has a build-in classifier which assigns packets coming from or 
sent to different machines to different classes. Either the MAC or IP and 
either source or destination addresses can be used. The MAC address can only 
be used when the Linux box is acting as an ethernet bridge, however. The 
classes are automatically assigned to machines based on the packets seen.
<P>The qdisc can be very useful at sites such as dorms where a lot of unrelated 
individuals share an Internet connection. A set of scripts setting up a 
relevant behavior for such a site is a central part of the WRR distribution.
<P>
<HR>
<A HREF="Adv-Routing-HOWTO-10.html"><IMG SRC="../img/next.gif" ALT="Next"></A>
<A HREF="Adv-Routing-HOWTO-8.html"><IMG SRC="../img/prev.gif" ALT="Previous"></A>
<A HREF="Adv-Routing-HOWTO.html#toc9"><IMG SRC="../img/toc.gif" ALT="Contents"></A>
<SCRIPT>EndPage();</SCRIPT>  </BODY>
</HTML>
